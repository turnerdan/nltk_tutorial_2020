{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR GOOGLE COLAB\n",
    "# If you are using Google Colab, first run the code cell below. You can run a cell by clicking in the cell and clicking on the arrow that appears on the left side of the cell. DO NOT run this cell if you are not using Google Colab.\n",
    "\n",
    "!wget \"https://raw.githubusercontent.com/turnerdan/nltk_tutorial_2020/master/shakespeare.txt\"\n",
    "!wget \"https://github.com/turnerdan/nltk_tutorial_2020/blob/master/shakespeare_raw.pkl?raw=true\"\n",
    "!wget \"https://github.com/turnerdan/nltk_tutorial_2020/blob/master/shakespeare_text.pkl?raw=true\"\n",
    "!wget \"https://github.com/turnerdan/nltk_tutorial_2020/blob/master/shakespeare_tokens.pkl?raw=true\"\n",
    "!wget \"https://raw.githubusercontent.com/turnerdan/nltk_tutorial_2020/master/walden.txt\"\n",
    "!wget \"https://github.com/turnerdan/nltk_tutorial_2020/blob/master/walden_clean_tokens.pkl?raw=true\"\n",
    "!wget \"https://github.com/turnerdan/nltk_tutorial_2020/blob/master/walden_raw.pkl?raw=true\"\n",
    "!wget \"https://github.com/turnerdan/nltk_tutorial_2020/blob/master/walden_text.pkl?raw=true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## Setup environment ##\n",
    "#######################\n",
    "\n",
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from scipy import special\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Shakespeare\n",
    "\n",
    "**Tokenize The Complete Works of William Shakespeare.**\n",
    "\n",
    "* Below I give the filepath to a plaintext version of the complete works of William Shakespeare.\n",
    "\n",
    "* Keep in mind that it will take a little while to run these scripts because this text file is larger than Walden.\n",
    "* Tokenization takes about 10 seconds and cleaning + plotting takes about two minutes.\n",
    "\n",
    "Answers are in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "## ## ## ## > Code it < ## ## ## ##                              #\n",
    "################################### \"Cleaning_Shakespeare_Timed\" #\n",
    "## Sample answer in /answer_keys ##                              #\n",
    "##################################################################\n",
    "\n",
    "######################\n",
    "## Read-in the file ##\n",
    "######################\n",
    "\n",
    "# What is the path to the complete works of Shakespeare?\n",
    "shakespeare_path = 'shakespeare.txt'\n",
    "\n",
    "# Open the file at the specified path\n",
    "shakespeare_file = open( shakespeare_path, 'r')\n",
    "\n",
    "# Read the file as raw text by calling the file with the read() function\n",
    "shakespeare_raw = \n",
    "\n",
    "# Close the original file with the close() function\n",
    "shakespeare_file.close()\n",
    "\n",
    "#######################\n",
    "## Tokenize the file ##\n",
    "#######################\n",
    "\n",
    "# Tokenize the raw text using word_tokenize()\n",
    "shakespeare_tokens = \n",
    "\n",
    "# Print a list of the tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the token frequency distribution for Shakespeare\n",
    "\n",
    "**Plot the 50 most frequent tokens in the complete works of William Shakespeare.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## Cleaning ##\n",
    "##############\n",
    "\n",
    "# Remove non-alphabetical characters using list comprehension\n",
    "shakespeare_tokens = [ token for token in shakespeare_tokens if token.isalpha() ]\n",
    "\n",
    "# Convert the text to lowercase using list comprehension\n",
    "shakespeare_tokens = [ token.lower() for token in shakespeare_tokens ]\n",
    "\n",
    "# Filter out stopwords using list comprehension\n",
    "shakespeare_tokens = [token for token in shakespeare_tokens if not token in set(stopwords.words('english'))]\n",
    "\n",
    "####################\n",
    "## Frequency plot ##\n",
    "####################\n",
    "\n",
    "# Generate a frequency distribution for the tokens\n",
    "\n",
    "\n",
    "# Display plot with top 50 tokens\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
